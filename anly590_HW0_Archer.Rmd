---
title: "Anly590_HW0_Archer"
author: "Alex Archer"
date: "9/18/2018"
output: rmarkdown::github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# 1
## 1.1

# Lasso

```{r, echo=TRUE}
# the Hitters dataset is in the ISLR package
library(ISLR)
library(glmnet)

# take a look at the variables
head(Hitters)

# remove categorical predictors
Hitters <- Hitters[,-c(14, 15, 20)]
Hitters <- na.omit(Hitters)

# set x and y to be passed into model
y <- Hitters$Salary
x <- model.matrix(Salary ~., Hitters)[,-1]

# creat and plot lasso
lasso.mod <- glmnet(x, y, alpha = 1)
#plot(lasso.mod, xvar = "lambda", lwd = 2)

# save image and place in markdown so it will show up in markdown file on github
dev.copy(png, "lassoco.png", width=8, height=6, units="in", res=100)
dev.off()
```

![Lasso Trajectories](lassoco.png)

From the trajectories of the coefficients in the mode, we can obtain an idea of how the lasso is doing variable selection. The penalty parameter is forcing the coefficients towards $0$.

```{r, echo=TRUE}
# find last 3 predictors in model
coef(lasso.mod)[,5]
```

The last $3$ variables in the model are Hits, CRuns, and CRBI.

Next, we want to find the optimal value of the regularization penalty using cross validation.

```{r, echo=TRUE}
# use cv to find optimal value of penalty
cv.lasso = cv.glmnet(x, y, alpha = 1)
#plot(cv.lasso)

# save image and place in markdown so it will show up in markdown file on github
dev.copy(png, "lassocv.png", width=8, height=6, units="in", res=100)
dev.off()

cv.lasso$lambda[28]
log(cv.lasso$lambda[28])

coef(lasso.mod)[,28]
```

![Lasso CV](lassocv.png)

The MSE, or mean squared error, sharply increases at around a value of $3$ for log(lambda). So the optimal value is approximately $\lambda = 20.7$. In the plot it is clear that this corresponds to $6$ predictors left in the model. The code above also shows that at this value of $\lambda$ there are $6$ predictors.

## 1.2

# Ridge

```{r, echo=TRUE}
# visualize ridge coef trajectories
ridge.mod <- glmnet(x, y, alpha = 0)
#plot(ridge.mod, xvar = "lambda", lwd = 2)
# save image and place in markdown so it will show up in markdown file on github
dev.copy(png, "ridgeco.png", width=8, height=6, units="in", res=100)
dev.off()
```

![Ridge Trajectories](ridgeco.png)

```{r, echo=TRUE}
# find optimal penalty
cv.lasso = cv.glmnet(x, y, alpha = 0)
#plot(cv.lasso)

# save image and place in markdown so it will show up in markdown file on github
dev.copy(png, "ridgecv.png", width=8, height=6, units="in", res=100)
dev.off()
```

![Ridge CV](ridgecv.png)

The optimal value for $\lambda$ in the ridge model appears to be pretty simlar.


The bias variance trade-off means that the realtionship between bias and variance in models is inverse. So if a model has low bias, it is likely sacrificing from high variance. As models become more complex and flexible they tend to have lower bias, but higher variance. The model can achieve low bias and can get so complex that it fits nearly every point in the data. But at this point, the model is overfit and has high variance. If new data were to be generated, the model would need to change drastically. There is also an issue if the model has extremely low variance but high bias. In this case, the model would likely not change much with new data, but it does not fit the data very well.

Thus regularization is a nice way to reduce the risk of overfitting, thus decresing the variance in models. The Lasso can also be used for model selection. As in number one, some variable coefficients were reduced to $0$ with the Lasso model. Additionally, in both the lasso and ridge models in Number $1$, the variance is being controlled by shrinking the coefficient estimates to $0$, when otherwise they may grow large. Finally, if we had a train and test set, we would find that prediction error is also lower when using regularization. 
